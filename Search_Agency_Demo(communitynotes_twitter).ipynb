{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhWHR/ZDyUyCWN3Py+7NlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/nfl-big-data-bowl-2024/blob/main/Search_Agency_Demo(communitynotes_twitter).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR669elMBjb1"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install pennylane\n",
        "!pip install pandas\n",
        "!pip install scikit-optimize\n",
        "!pip install ddg-scraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from skopt import gp_minimize\n",
        "import datetime\n",
        "import json\n",
        "from ddg_scraper import DuckScraper\n",
        "\n",
        "# Initialize the DuckDuckGo scraper\n",
        "duck_scraper = DuckScraper()\n",
        "\n",
        "# Function for an agent to perform a DuckDuckGo search\n",
        "def search_duckduckgo(query):\n",
        "    search_results = []\n",
        "    with duck_scraper.search(query) as results:\n",
        "        for result in results:\n",
        "            search_results.append({\n",
        "                'title': result.title,\n",
        "                'url': result.url,\n",
        "                'snippet': result.snippet\n",
        "            })\n",
        "    return search_results\n",
        "\n",
        "# Load API key from config.json\n",
        "try:\n",
        "    with open(\"/kaggle/input/config3/config.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "        openai.api_key = config[\"openai_api_key\"]\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the API key: {e}\")\n",
        "\n",
        "# Function to save results to a Markdown file\n",
        "def save_to_markdown_file(agent_prompts):\n",
        "    try:\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "        filename = f\"Results_{timestamp}.md\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(\"# GPT-4 Responses\\n\\n\")\n",
        "            for i, prompt in enumerate(agent_prompts):\n",
        "                f.write(f\"## Learning Round {i+1}\\n\")\n",
        "                f.write(f\"{prompt}\\n\\n\")\n",
        "        print(f\"Results saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Markdown file: {e}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "try:\n",
        "    df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2024/tackles.csv')\n",
        "    team_df = df[df['club'] == 'LA']\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "\n",
        "# Function to summarize tackle data\n",
        "def summarize_tackle_data(tackle_data_frame):\n",
        "    summary = tackle_data_frame.groupby(['gameId', 'nflId']).agg({\n",
        "        's': 'sum',\n",
        "        'a': 'sum'\n",
        "    }).reset_index()\n",
        "    summary_dict = summary.to_dict(orient='records')\n",
        "    return summary_dict\n",
        "\n",
        "# Function to calculate advanced performance metric\n",
        "def advanced_performance_metric(params):\n",
        "    try:\n",
        "        quantum_data = qnode(params)\n",
        "        tackle_data_summary = summarize_tackle_data(team_df)\n",
        "        speed_values = [x['s'] for x in tackle_data_summary]\n",
        "\n",
        "        mse = np.mean((np.array(quantum_data) - np.array(speed_values)) ** 2)\n",
        "\n",
        "        # Convert PennyLane tensor to Python float\n",
        "        mse_scalar = mse.item()\n",
        "\n",
        "        return mse_scalar\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in advanced_performance_metric: {e}\")\n",
        "        raise\n",
        "\n",
        "# Define a quantum circuit with PennyLane\n",
        "def quantum_circuit(params):\n",
        "    qml.RX(params[0], wires=0)\n",
        "    qml.RY(params[1], wires=1)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Initialize a quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2)\n",
        "\n",
        "# Create a QNode\n",
        "qnode = qml.QNode(quantum_circuit, dev)\n",
        "\n",
        "# Initialize learning rounds\n",
        "learning_rounds = 5\n",
        "\n",
        "# Initialize agent prompts and intercommunication data\n",
        "agent_prompts = []\n",
        "\n",
        "# Initialize POOLINSERT and HOLD cache\n",
        "pool_insert_cache = {}\n",
        "\n",
        "# System rules\n",
        "system_rules = \"\"\"System Rules:\n",
        "1. Agents must analyze quantum tackle data for advanced insights.\n",
        "2. Agents should employ advanced strategies for performance improvement.\n",
        "3. Agents will intercommunicate using a POOLINSERT and HOLD cache mechanism.\n",
        "4. This will be done over a series of learning rounds to contribute to collective understanding.\"\"\"\n",
        "\n",
        "# Main loop for learning rounds\n",
        "for round in range(learning_rounds):\n",
        "    # Optimize the parameters using Bayesian optimization\n",
        "    params = np.array([0.5, 0.1], requires_grad=True)\n",
        "    result = gp_minimize(lambda p: advanced_performance_metric(p), [(-3.14, 3.14), (-3.14, 3.14)], n_calls=10, random_state=0)\n",
        "    params = result.x\n",
        "\n",
        "    # Execute the quantum circuit to get the quantum_data\n",
        "    quantum_data = qnode(params)\n",
        "\n",
        "    # Update POOLINSERT cache\n",
        "    pool_insert_cache[f'Round_{round+1}'] = quantum_data.tolist()\n",
        "\n",
        "    # Summarize the tackle data for this round\n",
        "    tackle_data_summary = summarize_tackle_data(team_df)\n",
        "\n",
        "    # Generate prompts for the agents\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_rules},\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in advanced quantum and data analysis.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 1, provide an in-depth analysis of the following advanced quantum search result data: {quantum_data}. Summarized tackle data for this round is: {tackle_data_summary}. Also, suggest any data or insights that should be added to the POOLINSERT cache.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 2, based on Agent 1's analysis, elaborate on advanced strategies for performance improvement. Refer to POOLINSERT data: {pool_insert_cache}.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 3, offer a second opinion on the data analysis and strategies suggested by Agents 1 and 2. Cross-reference with POOLINSERT data: {pool_insert_cache}.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 4, considering the inputs from Agents 1, 2, and 3, provide a risk assessment based on the quantum and tackle data. Also, suggest any preventive measures.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 5, evaluate the efficiency of the current strategies based on the data and the inputs from all previous agents. Suggest improvements.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Agent 6, analyze the data for patterns or trends that could be useful for future games, integrating the insights from all previous agents.\"},\n",
        "        if round > 0:  # Starting from the second round, since we need previous data\n",
        "            previous_round_data = pool_insert_cache[f'Round_{round}']\n",
        "            search_query = f\"Advanced insights on {previous_round_data['some_key_from_analysis']}\"\n",
        "            duckduckgo_results = search_duckduckgo(search_query)\n",
        "\n",
        "            # Add the search results to the POOLINSERT cache for the next round\n",
        "            pool_insert_cache[f'Round_{round+1}_search_results'] = duckduckgo_results\n",
        "\n",
        "            # Now integrate these results into your agent prompts for the next round\n",
        "            messages.append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Agent 7, based on the analysis from the previous round, has crafted the following search query: '{search_query}'. The top search results are: {duckduckgo_results[:3]}\"  # Assuming we want the top 3 results\n",
        "            })\n",
        "    ]\n",
        "\n",
        "    # Make the GPT-4 Turbo API call\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=messages\n",
        "    )\n",
        "\n",
        "    # Store the GPT-4 Turbo response\n",
        "    agent_prompts.append(response['choices'][0]['message']['content'])\n",
        "\n",
        "# ... [The rest of your existing code] ...\n",
        "\n",
        "# Output the GPT-4 responses\n",
        "try:\n",
        "    for i, prompt in enumerate(agent_prompts):\n",
        "        print(f\"GPT-4 Response for Learning Round {i+1}: {prompt}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error printing GPT-4 responses: {e}\")\n",
        "\n",
        "# Save the results to a Markdown file\n",
        "try:\n",
        "    save_to_markdown_file(agent_prompts)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving to Markdown file: {e}\")\n"
      ],
      "metadata": {
        "id": "zduMWx2LBjz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}